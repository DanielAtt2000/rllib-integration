022-12-13 23:21:38,272	WARNING worker.py:1839 --
The node with node id: a6f8436d10af5fbd3ced0013b768fdd2ad5083ac54e2f91ff101641e and a
ddress: 192.168.1.205 and node name: 192.168.1.205
has been marked dead because the detector has missed too many heartbeats from it.
This can happen when a 	(1) raylet crashes unexpectedly (OOM, preempted node, etc.)
	(2) raylet has lagging heartbeats due to slow network or busy workload.

2022-12-13 23:21:58,030	WARNING worker.py:1839 -- Raylet is terminated:
 ip=192.168.1.205, id=a6f8436d10af5fbd3ced0013b768fdd2ad5083ac54e2f91ff101641e.
 Termination is unexpected. Possible reasons include: (
 1) SIGKILL by the user or system OOM killer, (
 2) Invalid memory access from Raylet causing SIGSEGV or SIGBUS,
 (3) Other termination signals. Last 20 lines of the Raylet logs:
    [2022-12-13 23:21:29,299 C 11595 11664] (raylet) node_manager.cc:173: This node has beem marked as dead.
    *** StackTrace Information ***
    /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x49beda) [0x556d6cf5beda] ray::operator<<()
    /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x49d9b2) [0x556d6cf5d9b2] ray::SpdLogMessage::Flush()
    /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x49dcc7) [0x556d6cf5dcc7] ray::RayLog::~RayLog()
    /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x241d74) [0x556d6cd01d74] std::_Function_handler<>::_M_invoke()
    /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x375bd4) [0x556d6ce35bd4] std::_Function_handler<>::_M_invoke()
    /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x3cabe0) [0x556d6ce8abe0] ray::rpc::GcsRpcClient::ReportHeartbeat()::{lambda()#2}::operator()()
    /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x373a42) [0x556d6ce33a42] ray::rpc::ClientCallImpl<>::OnReplyReceived()
    /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x228285) [0x556d6cce8285] std::_Function_handler<>::_M_invoke()
    /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x47fcf6) [0x556d6cf3fcf6] EventTracker::RecordExecution()
    /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x42031e) [0x556d6cee031e] std::_Function_handler<>::_M_invoke()
    /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x420796) [0x556d6cee0796] boost::asio::detail::completion_handler<>::do_complete()
    /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x9adbcb) [0x556d6d46dbcb] boost::asio::detail::scheduler::do_run_one()
    /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x9af391) [0x556d6d46f391] boost::asio::detail::scheduler::run()
    /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x9af5c0) [0x556d6d46f5c0] boost::asio::io_context::run()
    /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x9fe2d0) [0x556d6d4be2d0] execute_native_thread_routine
    /lib/x86_64-linux-gnu/libpthread.so.0(+0x76db) [0x7f66bf09c6db] start_thread
    /lib/x86_64-linux-gnu/libc.so.6(clone+0x3f) [0x7f66be27e61f] __clone


(RolloutWorker pid=16911) ====> REWARD Done idle
(RolloutWorker pid=16911) Reward: -10000.1
(RolloutWorker pid=16911) Truck spawned!
(RolloutWorker pid=16911) Passed Waypoint <------------
(RolloutWorker pid=16911) Passed Waypoint <------------
(RolloutWorker pid=16911) hyp_distance_to_next_waypoint = 476.14195158595606
(RolloutWorker pid=16911) ====> REWARD for angle (1.97144) to center line 91.30397
(RolloutWorker pid=16911) Reward: 567.4459228691397
(RolloutWorker pid=16911) Passed Waypoint <------------
(RolloutWorker pid=16911) hyp_distance_to_next_waypoint = 122.52218140412796
(RolloutWorker pid=16911) ====> REWARD for angle (1.32535) to center line 135.81275
(RolloutWorker pid=16911) Reward: 258.3349282563471
(RolloutWorker pid=16911) Passed Waypoint <------------
(RolloutWorker pid=16911) hyp_distance_to_next_waypoint = 62.315567171089604
(RolloutWorker pid=16911) ====> REWARD for angle (70.39171) to center line 2.55712
(RolloutWorker pid=16911) Reward: 64.87268643202962
(RolloutWorker pid=16911) hyp_distance_to_next_waypoint = 62.32042776544583
(RolloutWorker pid=16911) ====> REWARD for angle (70.35759) to center line 2.55836
(RolloutWorker pid=16911) Reward: 64.87878702082449
(raylet) [2022-12-13 23:21:29,299 C 11595 11664] (raylet) node_manager.cc:173: This node has beem marked as dead.
(raylet) *** StackTrace Information ***
(raylet) /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x49beda) [0x556d6cf5beda] ray::operator<<()
(raylet) /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x49d9b2) [0x556d6cf5d9b2] ray::SpdLogMessage::Flush()
(raylet) /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x49dcc7) [0x556d6cf5dcc7] ray::RayLog::~RayLog()
(raylet) /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x241d74) [0x556d6cd01d74] std::_Function_handler<>::_M_invoke()
(raylet) /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x375bd4) [0x556d6ce35bd4] std::_Function_handler<>::_M_invoke()
(raylet) /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x3cabe0) [0x556d6ce8abe0] ray::rpc::GcsRpcClient::ReportHeartbeat()::{lambda()#2}::operator()()
(raylet) /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x373a42) [0x556d6ce33a42] ray::rpc::ClientCallImpl<>::OnReplyReceived()
(raylet) /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x228285) [0x556d6cce8285] std::_Function_handler<>::_M_invoke()
(raylet) /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x47fcf6) [0x556d6cf3fcf6] EventTracker::RecordExecution()
(raylet) /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x42031e) [0x556d6cee031e] std::_Function_handler<>::_M_invoke()
(raylet) /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x420796) [0x556d6cee0796] boost::asio::detail::completion_handler<>::do_complete()
(raylet) /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x9adbcb) [0x556d6d46dbcb] boost::asio::detail::scheduler::do_run_one()
(raylet) /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x9af391) [0x556d6d46f391] boost::asio::detail::scheduler::run()
(raylet) /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x9af5c0) [0x556d6d46f5c0] boost::asio::io_context::run()
(raylet) /home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/core/src/ray/raylet/raylet(+0x9fe2d0) [0x556d6d4be2d0] execute_native_thread_routine
(raylet) /lib/x86_64-linux-gnu/libpthread.so.0(+0x76db) [0x7f66bf09c6db] start_thread
(raylet) /lib/x86_64-linux-gnu/libc.so.6(clone+0x3f) [0x7f66be27e61f] __clone
(raylet)
== Status ==
Current time: 2022-12-13 23:22:29 (running for 03:58:57.91)
Memory usage on this node: 5.9/15.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 12.0/12 CPUs, 1.0/1 GPUs, 0.0/7.22 GiB heap, 0.0/3.61 GiB objects (0.0/1.0 accelerator_type:G)
Result logdir: /home/daniel/ray_results/carla_rllib/dqn_39404c03df
Number of trials: 1/1 (1 RUNNING)
+---------------------------------------+----------+---------------------+--------+------------------+-------+----------+------------------------+----------------------+----------------------+
| Trial name                            | status   | loc                 |   iter |   total time (s) |    ts |   reward |   num_recreated_worker |   episode_reward_max |   episode_reward_min |
|                                       |          |                     |        |                  |       |          |                      s |                      |                      |
|---------------------------------------+----------+---------------------+--------+------------------+-------+----------+------------------------+----------------------+----------------------|
| CustomDQNTrainer_CarlaEnv_3f1a8_00000 | RUNNING  | 192.168.1.205:12049 |     70 |          14103.8 | 70560 | -8908.76 |                      0 |             -7250.01 |             -9104.97 |
+---------------------------------------+----------+---------------------+--------+------------------+-------+----------+------------------------+----------------------+----------------------+


2022-12-13 23:22:30,259	WARNING resource_updater.py:50 -- Cluster resources not detected or are 0. Attempt #2...
2022-12-13 23:22:30,984	WARNING resource_updater.py:50 -- Cluster resources not detected or are 0. Attempt #3...
2022-12-13 23:22:31,485	WARNING resource_updater.py:50 -- Cluster resources not detected or are 0. Attempt #4...
2022-12-13 23:22:31,986	WARNING resource_updater.py:50 -- Cluster resources not detected or are 0. Attempt #5...
2022-12-13 23:22:32,487	WARNING resource_updater.py:63 -- Cluster resources cannot be detected or are 0. You can resume this experiment by passing in `resume=True` to `run`.
2022-12-13 23:22:32,520	WARNING util.py:244 -- The `on_step_begin` operation took 2.513 s, which may be a performance bottleneck.
2022-12-13 23:22:33,442	ERROR trial_runner.py:993 -- Trial CustomDQNTrainer_CarlaEnv_3f1a8_00000: Error processing event.
ray.tune.error._TuneNoNextExecutorEventError: Traceback (most recent call last):
  File "/home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/tune/execution/ray_trial_executor.py", line 1050, in get_next_executor_event
    future_result = ray.get(ready_future)
  File "/home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 105, in wrapper
    return func(*args, **kwargs)
  File "/home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/_private/worker.py", line 2291, in get
    raise value
ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.
	class_name: CustomDQNTrainer
	actor_id: 8fa45c255f2ad9f7d579e9cb01000000
	pid: 12049
	namespace: 2f1483e3-fb97-4478-9704-388824f02ded
	ip: 192.168.1.205
The actor is dead because its owner has died. Owner Id: 01000000ffffffffffffffffffffffffffffffffffffffffffffffff#
 Owner Ip address: 192.168.1.205 Owner worker exit type: SYSTEM_ERROR Worker exit detail: Owner's node has crashed.

Result for CustomDQNTrainer_CarlaEnv_3f1a8_00000:
  agent_timesteps_total: 70560
  counters:
    last_target_update_ts: 70128
    num_agent_steps_sampled: 70560
    num_agent_steps_trained: 69568
    num_env_steps_sampled: 70560
    num_env_steps_trained: 69568
    num_target_updates: 136
  custom_metrics:
    angle_with_center_max: 0.3896236717700958
    angle_with_center_mean: 0.3714585602283478
    angle_with_center_min: 0.2563650906085968
  date: 2022-12-13_23-19-38
  done: false
  episode_len_mean: 537.3
  episode_media: {}
  episode_reward_max: -7250.013466468994
  episode_reward_mean: -8908.76479249178
  episode_reward_min: -9104.967675421673
  episodes_this_iter: 2
  episodes_total: 237
  experiment_id: a4e41227124a428898b2fc90d82c8ef4
  experiment_tag: '0'
  hostname: daniel-AORUS-5-SB
  info:
    last_target_update_ts: 70128
    learner:
      default_policy:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.1
          grad_gnorm: 40.0
          max_q: 1495503744.0
          mean_q: 1495503744.0
          min_q: 1495503744.0
        mean_td_error: -61836928.0
        model: {}
        num_agent_steps_trained: 16.0
        td_error: [-61836928.0, -61836928.0, -61836928.0, -61836928.0, -61836928.0,
          -61836928.0, -61836928.0, -61836928.0, -61836928.0, -61836928.0, -61836928.0,
          -61836928.0, -61836928.0, -61836928.0, -61836928.0, -61836928.0]
    num_agent_steps_sampled: 70560
    num_agent_steps_trained: 69568
    num_env_steps_sampled: 70560
    num_env_steps_trained: 69568
    num_target_updates: 136
  iterations_since_restore: 70
  node_ip: 192.168.1.205
  num_agent_steps_sampled: 70560
  num_agent_steps_trained: 69568
  num_env_steps_sampled: 70560
  num_env_steps_sampled_this_iter: 1008
  num_env_steps_trained: 69568
  num_env_steps_trained_this_iter: 1008
  num_faulty_episodes: 0
  num_healthy_workers: 1
  num_recreated_workers: 0
  num_steps_trained_this_iter: 1008
  perf:
    cpu_util_percent: 4.538823529411765
    ram_util_percent: 69.05176470588236
  pid: 12049
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.04680184794435377
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 157.06619813573673
    mean_inference_ms: 3.1042162890744276
    mean_raw_obs_processing_ms: 5.753951013744012
  sampler_results:
    custom_metrics:
      angle_with_center_max: 0.3896236717700958
      angle_with_center_mean: 0.3714585602283478
      angle_with_center_min: 0.2563650906085968
    episode_len_mean: 537.3
    episode_media: {}
    episode_reward_max: -7250.013466468994
    episode_reward_mean: -8908.76479249178
    episode_reward_min: -9104.967675421673
    episodes_this_iter: 2
    hist_stats:
      episode_lengths: [95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 96, 120, 609,
        609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609,
        609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609,
        609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609,
        609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609,
        609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609,
        609, 609, 609, 609, 609]
      episode_reward: [-7771.375494684929, -7771.375494684929, -7771.375494684929, -7771.375494684929,
        -7771.375494684929, -7771.375494684929, -7771.375494684929, -7771.375494684929,
        -7771.375494684929, -7771.375494684929, -7771.375494684929, -7771.375494684929,
        -7342.739760226181, -7250.013466468994, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673,
        -9104.967675421673, -9104.967675421673, -9104.967675421673, -9104.967675421673]
    num_faulty_episodes: 0
    policy_reward_max: {}
    policy_reward_mean: {}
    policy_reward_min: {}
    sampler_perf:
      mean_action_processing_ms: 0.04680184794435377
      mean_env_render_ms: 0.0
      mean_env_wait_ms: 157.06619813573673
      mean_inference_ms: 3.1042162890744276
      mean_raw_obs_processing_ms: 5.753951013744012
  time_since_restore: 14103.832560777664
  time_this_iter_s: 179.1054139137268
  time_total_s: 14103.832560777664
  timers:
    learn_throughput: 37.225
    learn_time_ms: 429.823
    load_throughput: 121728.395
    load_time_ms: 0.131
    synch_weights_time_ms: 1.763
    training_iteration_time_ms: 2828.49
  timestamp: 1670969978
  timesteps_since_restore: 0
  timesteps_total: 70560
  training_iteration: 70
  trial_id: 3f1a8_00000
  warmup_time: 28.26146101951599

== Status ==
Current time: 2022-12-13 23:22:35 (running for 03:59:04.59)
Memory usage on this node: 5.9/15.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/0 CPUs, 0/0 GPUs, 0.0/0.0 GiB heap, 0.0/0.0 GiB objects
Result logdir: /home/daniel/ray_results/carla_rllib/dqn_39404c03df
Number of trials: 1/1 (1 ERROR)
+---------------------------------------+----------+---------------------+--------+------------------+-------+----------+------------------------+----------------------+----------------------+
| Trial name                            | status   | loc                 |   iter |   total time (s) |    ts |   reward |   num_recreated_worker |   episode_reward_max |   episode_reward_min |
|                                       |          |                     |        |                  |       |          |                      s |                      |                      |
|---------------------------------------+----------+---------------------+--------+------------------+-------+----------+------------------------+----------------------+----------------------|
| CustomDQNTrainer_CarlaEnv_3f1a8_00000 | ERROR    | 192.168.1.205:12049 |     70 |          14103.8 | 70560 | -8908.76 |                      0 |             -7250.01 |             -9104.97 |
+---------------------------------------+----------+---------------------+--------+------------------+-------+----------+------------------------+----------------------+----------------------+
Number of errored trials: 1
+---------------------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------+
| Trial name                            |   # failures | error file                                                                                                                |
|---------------------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------|
| CustomDQNTrainer_CarlaEnv_3f1a8_00000 |            1 | /home/daniel/ray_results/carla_rllib/dqn_39404c03df/CustomDQNTrainer_CarlaEnv_3f1a8_00000_0_2022-12-13_19-23-31/error.txt |
+---------------------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------+

== Status ==
Current time: 2022-12-13 23:27:31 (running for 04:04:00.42)
Memory usage on this node: 6.2/15.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/0 CPUs, 0/0 GPUs, 0.0/0.0 GiB heap, 0.0/0.0 GiB objects
Result logdir: /home/daniel/ray_results/carla_rllib/dqn_39404c03df
Number of trials: 1/1 (1 ERROR)
+---------------------------------------+----------+---------------------+--------+------------------+-------+----------+------------------------+----------------------+----------------------+
| Trial name                            | status   | loc                 |   iter |   total time (s) |    ts |   reward |   num_recreated_worker |   episode_reward_max |   episode_reward_min |
|                                       |          |                     |        |                  |       |          |                      s |                      |                      |
|---------------------------------------+----------+---------------------+--------+------------------+-------+----------+------------------------+----------------------+----------------------|
| CustomDQNTrainer_CarlaEnv_3f1a8_00000 | ERROR    | 192.168.1.205:12049 |     70 |          14103.8 | 70560 | -8908.76 |                      0 |             -7250.01 |             -9104.97 |
+---------------------------------------+----------+---------------------+--------+------------------+-------+----------+------------------------+----------------------+----------------------+
Number of errored trials: 1
+---------------------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------+
| Trial name                            |   # failures | error file                                                                                                                |
|---------------------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------|
| CustomDQNTrainer_CarlaEnv_3f1a8_00000 |            1 | /home/daniel/ray_results/carla_rllib/dqn_39404c03df/CustomDQNTrainer_CarlaEnv_3f1a8_00000_0_2022-12-13_19-23-31/error.txt |
+---------------------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------+

2022-12-13 23:27:31,733	ERROR ray_trial_executor.py:111 -- An exception occurred when trying to stop the Ray actor:Traceback (most recent call last):
  File "/home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/tune/execution/ray_trial_executor.py", line 102, in _post_stop_cleanup
    ray.get(future, timeout=timeout)
  File "/home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 105, in wrapper
    return func(*args, **kwargs)
  File "/home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/_private/worker.py", line 2291, in get
    raise value
ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.
	class_name: CustomDQNTrainer
	actor_id: 8fa45c255f2ad9f7d579e9cb01000000
	pid: 12049
	namespace: 2f1483e3-fb97-4478-9704-388824f02ded
	ip: 192.168.1.205
The actor is dead because its owner has died. Owner Id: 01000000ffffffffffffffffffffffffffffffffffffffffffffffff Owner Ip address: 192.168.1.205 Owner worker exit type: SYSTEM_ERROR Worker exit detail: Owner's node has crashed.


done.
Traceback (most recent call last):
  File "dqn_train.py", line 119, in <module>
    main()
  File "dqn_train.py", line 114, in main
    run(args)
  File "dqn_train.py", line 39, in run
    tune.run(CustomDQNTrainer,
  File "/home/daniel/anaconda3/envs/CarlaRlib/lib/python3.8/site-packages/ray/tune/tune.py", line 771, in run
    raise TuneError("Trials did not complete", incomplete_trials)
ray.tune.error.TuneError: ('Trials did not complete', [Cust